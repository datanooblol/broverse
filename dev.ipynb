{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df2a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63999e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broverse.action import Action\n",
    "from broverse.flow import Flow\n",
    "from broverse.bedrock import BedrockChat\n",
    "from typing import Any\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88a7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputAction(Action):\n",
    "    def run(self, shared):\n",
    "        message = input(\"You: \")\n",
    "        shared['input'] = message\n",
    "        return message\n",
    "\n",
    "    def validate_next_action(self, inputs: Any) -> str:\n",
    "        if \"exit\" == inputs.lower():\n",
    "            return \"end\"\n",
    "        return \"router\"\n",
    "    \n",
    "class RouterAction(Action):\n",
    "    def __init__(self, system_prompt:str, model:BedrockChat):\n",
    "        super().__init__()\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = model\n",
    "\n",
    "    def run(self, shared):\n",
    "        input_message = shared.get(\"input\", \"No message\")\n",
    "        intent = self.model.run(self.system_prompt, [self.model.UserMessage(text=input_message)])\n",
    "        intent = intent.split(\"```yaml\")[1].split(\"```\")[0].strip()\n",
    "        intent = yaml.safe_load(intent)['action']\n",
    "        print(\"Intent:\", intent)\n",
    "        return intent\n",
    "    \n",
    "    def validate_next_action(self, inputs:Any) -> str:\n",
    "        if inputs == 'farewell':\n",
    "            return 'farewell'\n",
    "        return \"chat\"\n",
    "\n",
    "class ChatAction(Action):\n",
    "    def __init__(self, system_prompt:str, model:BedrockChat):\n",
    "        super().__init__()\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = model\n",
    "    \n",
    "    def run(self, shared):\n",
    "        if \"messages\" not in shared:\n",
    "            shared[\"messages\"] = []\n",
    "        input_message = shared.get(\"input\", \"No message\")\n",
    "        shared[\"messages\"].append(self.model.UserMessage(text=input_message))\n",
    "        ai_response = self.model.run(self.system_prompt, shared[\"messages\"])\n",
    "        shared[\"messages\"].append(self.model.AIMessage(text=ai_response))\n",
    "        print(\"AI:\", ai_response)\n",
    "        return ai_response\n",
    "    \n",
    "    def validate_next_action(self, inputs: Any) -> str:\n",
    "        return \"continue\"\n",
    "    \n",
    "class FarewellAction(Action):\n",
    "    def __init__(self, system_prompt:str, model:BedrockChat):\n",
    "        super().__init__()\n",
    "        self.system_prompt = system_prompt\n",
    "        self.model = model    \n",
    "\n",
    "    def run(self, shared):\n",
    "        if \"messages\" not in shared:\n",
    "            shared[\"messages\"] = []\n",
    "        input_message = shared.get(\"input\", \"No message\")\n",
    "        shared[\"messages\"].append(self.model.UserMessage(text=f\"{input_message}\\n\\nI gotta go now. See ya next time.\"))\n",
    "        ai_response = self.model.run(self.system_prompt, shared[\"messages\"])\n",
    "        shared[\"messages\"].append(self.model.AIMessage(text=ai_response))\n",
    "        print(\"AI:\", ai_response)\n",
    "        return ai_response\n",
    "    \n",
    "    def validate_next_action(self, inputs: Any) -> str:\n",
    "        return \"end\"\n",
    "\n",
    "class End(Action):\n",
    "    def run(self, shared):\n",
    "        return None\n",
    "\n",
    "router_prompt = \"\"\"\\\n",
    "classify a user's intent based on the input messages. \n",
    "Intent options are:\n",
    "1. continue if nothing goes wrong\n",
    "2. farewell if a user's message indicate that he or she wants to go somewhere\n",
    "\n",
    "Return your response in codeblock with this following yaml format:\n",
    "```yaml\n",
    "action: either continue or farewell\n",
    "```\n",
    "\n",
    "IMPORTANT: Make sure to:\n",
    "1. Use proper indentation (4 spaces) for all multi-line fields\n",
    "2. Use the | character for multi-line text fields\n",
    "3. Keep single-line fields without the | character\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1acd3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_action = InputAction()\n",
    "chat_action = ChatAction(\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    "    model=BedrockChat()\n",
    ")\n",
    "router_action = RouterAction(\n",
    "    system_prompt=router_prompt,\n",
    "    model=BedrockChat()\n",
    ")\n",
    "\n",
    "farewell_action = FarewellAction(\n",
    "    system_prompt=\"Your job is to farewell a user.\",\n",
    "    model=BedrockChat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09887cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_action -\"router\">> router_action\n",
    "router_action -\"chat\">> chat_action\n",
    "router_action -\"farewell\">> farewell_action\n",
    "chat_action -\"continue\">> input_action\n",
    "\n",
    "for action in [input_action, farewell_action]:\n",
    "    action -\"end\">> End()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ef6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Flow(start_action=input_action)\n",
    "flow.save_mermaid(filename=\"flow_chart.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fde832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```mermaid\n",
      "flowchart TD\n",
      "    InputAction -->|router| RouterAction\n",
      "    RouterAction -->|chat| ChatAction\n",
      "    ChatAction -->|continue| InputAction\n",
      "    RouterAction -->|farewell| FarewellAction\n",
      "    FarewellAction -->|end| End\n",
      "    InputAction -->|end| End\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "chart = flow.to_mermaid()\n",
    "print(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5ba58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: farewell\n",
      "AI: It was nice chatting with you. Have a great day and I'll see you next time!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = {}\n",
    "flow.run(shared=shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87db382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\broverse\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode([\"text1\", \"text2\"])  # Done!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fe213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, (2, 384), 384)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0]), embeddings.shape, embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b0e07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c894a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "dynamodb = boto3.resource('dynamodb', region_name='ap-southeast-1')\n",
    "# table = dynamodb.Table(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1576d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dynamodb.Table(\"test-broverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d97215c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broverse.program.dynamodb import create_document, update_document_status, delete_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71fde778",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_document(\n",
    "    user_id=\"000\",\n",
    "    document_id=\"555\",\n",
    "    username=\"admin\",\n",
    "    file_path=\"test-file\",\n",
    "    vector_path=\"test-vector\",\n",
    "    status=\"CREATED\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24589be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_document_status(user_id=\"000\", document_id=\"555\", new_status=\"READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aa24818",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_document(user_id=\"000\", document_id=\"555\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e6d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\broverse\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode([\"text1\", \"text2\"])  # Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f202764",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Hello there\",\n",
    "    \"I'm hungry\",\n",
    "    \"Oh my god, are you ok?\"\n",
    "]\n",
    "\n",
    "vectors = model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20109ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = []\n",
    "enum = 0\n",
    "for t, v in zip(texts, vectors):\n",
    "    obj = {\"key\": f\"v{enum}\", \"data\": {\"float32\": v.tolist()}, \"metadata\": {\"id\": f\"key{enum}\", \"source_text\": t, \"source\": \"url\"}}\n",
    "    embedding_vectors.append(obj)\n",
    "    enum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7250c0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'fcc16795-a2fa-463f-bede-28901d6d5b73',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Mon, 28 Jul 2025 17:25:53 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amz-request-id': 'fcc16795-a2fa-463f-bede-28901d6d5b73',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'vary': 'origin, access-control-request-method, access-control-request-headers',\n",
       "   'access-control-expose-headers': '*'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create S3Vectors client\n",
    "s3vectors = boto3.client('s3vectors', region_name='us-west-2')\n",
    "\n",
    "# Insert vector embedding\n",
    "s3vectors.put_vectors( vectorBucketName=\"test-broverse-20250729\",\n",
    "  indexName=\"test-url-index\", \n",
    "  vectors=embedding_vectors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddf68443",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"I'm straving\"\n",
    "vector = model.encode([input_query])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c33327f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'v1', 'metadata': {'source': 'url', 'source_text': \"I'm hungry\", 'id': 'key1'}, 'distance': 0.5873361825942993}, {'key': 'v2', 'metadata': {'source_text': 'Oh my god, are you ok?', 'source': 'url', 'id': 'key2'}, 'distance': 0.7358927130699158}, {'key': 'v0', 'metadata': {'source_text': 'Hello there', 'source': 'url', 'id': 'key0'}, 'distance': 0.777753472328186}]\n"
     ]
    }
   ],
   "source": [
    "# Performa a similarity query. You can also optionally use a filter in your query\n",
    "query = s3vectors.query_vectors( vectorBucketName=\"test-broverse-20250729\",\n",
    "  indexName=\"test-url-index\",\n",
    "  queryVector={\"float32\":vector},\n",
    "  topK=3, \n",
    "  filter={\"source\":\"url\"},\n",
    "  returnDistance=True,\n",
    "  returnMetadata=True\n",
    "  )\n",
    "results = query[\"vectors\"]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef0ed271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broverse.program.s3vector import save_to_s3_vectors, query_from_s3_vectors\n",
    "from broverse.interface import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "613254a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0a284fc9-d3a3-4400-87b3-1291c145ea6e',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Mon, 28 Jul 2025 17:58:10 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amz-request-id': '0a284fc9-d3a3-4400-87b3-1291c145ea6e',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'vary': 'origin, access-control-request-method, access-control-request-headers',\n",
       "   'access-control-expose-headers': '*'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = [\n",
    "    Context(context=\"I'm straving\", metadata={\"source\": \"url\"}),\n",
    "    Context(context=\"I see death people\", metadata={\"source\": \"url\"}),\n",
    "    Context(context=\"Those puppies are cute\", metadata={\"source\": \"url\"}),\n",
    "]\n",
    "\n",
    "vectors = model.encode([context.context for context in contexts])\n",
    "save_to_s3_vectors(contexts, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91eb30b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broverse.program.s3vector import save_to_s3_vectors, query_from_s3_vectors\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode([\"text1\", \"text2\"])  # Done!\n",
    "\n",
    "user_query = \"What is agentic AI?\"\n",
    "vector = model.encode([user_query])[0].tolist()\n",
    "response = query_from_s3_vectors(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cf0db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(context='and provide comprehensive solutions for AI workloads.\\n\\n**Create Amazon Bedrock Knowledge Bases with S3 Vectors**\\n\\n You can use S3 Vectors in Amazon Bedrock Knowledge Bases to simplify and reduce the cost of vector storage for RAG applications. When creating a knowledge base in the Amazon Bedrock console, you can choose the S3 vector bucket as your vector store option.\\n\\nIn **Step 3**, you can choose the **Vector store creation method** either to create an S3 vector bucket and vector index or choose the existing S3 vector bucket and vector index that you’ve previously created.\\n\\n\\n\\nFor detailed step-by-step instructions, visit Create a knowledge base by connecting to a data source in Amazon Bedrock Knowledge Basesin the Amazon Bedrock User Guide.\\n\\n**Using Amazon SageMaker Unified Studio**You can create and manage knowledge bases with S3 Vectors in Amazon SageMaker Unified Studio when you build your generative AI applications through Amazon Bedrock. SageMaker Unified Studio is available in', id='5a7bf16e-e253-4523-b077-58b2f565a76b', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 11, 'id': '29dd0613-9ad7-4536-a8d1-bd0258cc120f'}, type='document'),\n",
       " Context(context='source in Amazon Bedrock Knowledge Basesin the Amazon Bedrock User Guide.\\n\\n**Using Amazon SageMaker Unified Studio**You can create and manage knowledge bases with S3 Vectors in Amazon SageMaker Unified Studio when you build your generative AI applications through Amazon Bedrock. SageMaker Unified Studio is available in the next generation of Amazon SageMaker and provides a unified development environment for data and AI, including building and texting generative AI applications that use Amazon Bedrock knowledge bases.\\n\\n\\n\\nYou can choose **Amazon S3 Vectors** as the **Vector store** when you create a new knowledge bases in the SageMaker Unified Studio. To learn more, visit Add an Amazon Bedrock Knowledge Base component to a chat agent app in the Amazon SageMaker Unified Studio User Guide.\\n\\n**Export S3 vector data to Amazon OpenSearch Service**You can balance cost and performance by adopting a tiered strategy that stores long-term vector data cost-effectively in Amazon S3 while exporting high priority vectors', id='6eae8650-d0f8-4123-9ff7-c21c299108b6', metadata={'id': '44818c38-d1fe-4fa0-a603-ac580d24fd37', 'sequence': 12, 'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/'}, type='document'),\n",
       " Context(context='cost-effective Retrieval-Augmented Generation (RAG) applications. Through its integration with Amazon OpenSearch Service, you can lower storage costs by keeping infrequent queried vectors in S3 Vectors and then quickly move them to OpenSearch as demands increase or to support real-time, low-latency search operations.\\n\\nWith S3 Vectors, you can now economically store the vector embeddings that represent massive amounts of unstructured data such as images, videos, documents, and audio files, enabling scalable generative AI applications including semantic and similarity search, RAG, and build agent memory. You can also build applications to support a wide range of industry use cases including personalized recommendations, automated content analysis, and intelligent document processing without the complexity and cost of managing vector databases.\\n\\n**S3 Vectors in action**\\n\\n To create a vector bucket, choose **Vector buckets** in the left navigation pane in the Amazon S3 console and then choose **Create vector bucket**.\\n\\nEnter a vector bucket name and choose the encryption', id='cd4bdad0-5628-40e7-ad54-fa5306592a71', metadata={'sequence': 3, 'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'id': 'a77d0e17-cb03-4062-babf-cc3805f85a2e'}, type='document'),\n",
       " Context(context='Hello there', id='1efdc695-79c0-4492-beeb-51536c8516fe', metadata={'id': 'key0', 'source': 'url'}, type='document'),\n",
       " Context(context='component to a chat agent app in the Amazon SageMaker Unified Studio User Guide.\\n\\n**Export S3 vector data to Amazon OpenSearch Service**You can balance cost and performance by adopting a tiered strategy that stores long-term vector data cost-effectively in Amazon S3 while exporting high priority vectors to OpenSearch for real-time query performance.\\n\\nThis flexibility means your organizations can access OpenSearch’s high performance (high QPS, low latency) for critical, real-time applications, such as product recommendations or fraud detection, while keeping less time-sensitive data in S3 Vectors.\\n\\nTo export your vector index, choose **Advanced search export**, then choose **Export to OpenSearch** in the Amazon S3 console.\\n\\n\\n\\nThen, you will be brought to the Amazon OpenSearch Service Integration console with a template for S3 vector index export to OpenSearch vector engine. Choose **Export** with pre-selected S3 vector source and a service access role.\\n\\n\\n\\nIt will start the steps to create a new OpenSearch Serverless collection and migrate data', id='12ae4ada-be47-4dd0-96c0-b8ebf68171e8', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 13, 'id': 'b1b92359-0fe2-4b91-8926-84aade481bd9'}, type='document'),\n",
       " Context(context='Title: Introducing Amazon S3 Vectors: First cloud storage with native vector support at scale (preview) | Amazon Web Services\\n\\nURL Source: https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/\\n\\nPublished Time: 2025-07-15T16:33:32-07:00\\n\\nMarkdown Content:\\n![Image 1: Voiced by Polly](https://aws.amazon.com/polly/)\\n\\nToday, we’re announcing the preview of Amazon S3 Vectors, a purpose-built durable vector storage solution that can reduce the total cost of uploading, storing, and querying vectors by up to 90 percent. Amazon S3 Vectors is the first cloud object store with native support to store large vector datasets and provide subsecond query performance that makes it affordable for businesses to store AI-ready data at massive scale.\\n\\nVector search is an emerging technique used in generative AI applications to find similar data points to given data by comparing their vector representations using distance or similarity metrics. Vectors are numerical representation of unstructured data created from embedding models. You use embedding models to generate vector embeddings of your data and store them in S3 Vectors', id='6eedd9fa-02eb-445a-bb12-c4a0bb5c7bc3', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 0, 'id': '5f92cbef-0f42-4446-82d8-fa4b90ca9a0f'}, type='document'),\n",
       " Context(context='= query[\"vectors\"]\\nprint(results)\\n```\\n\\nPython\\n\\nTo learn more about inserting vectors into a vector index, or listing, querying, and deleting vectors, visit S3 vector buckets and S3 vector indexes in the Amazon S3 User Guide. Additionally, with the S3 Vectors embed command line interface (CLI), you can create vector embeddings for your data using Amazon Bedrock and store and query them in an S3 vector index using single commands. For more information, see the S3 Vectors Embed CLI GitHub repository.\\n\\n**Integrate S3 Vectors with other AWS services**\\n\\n S3 Vectors integrates with other AWS services such as Amazon Bedrock, Amazon SageMaker, and Amazon OpenSearch Service to enhance your vector processing capabilities and provide comprehensive solutions for AI workloads.\\n\\n**Create Amazon Bedrock Knowledge Bases with S3 Vectors**\\n\\n You can use S3 Vectors in Amazon Bedrock Knowledge Bases to simplify and reduce the cost of vector storage for RAG applications. When creating a knowledge base in the Amazon Bedrock', id='3f960071-f43d-4869-814a-c7ed4b31980b', metadata={'id': 'cf42dc06-4527-4419-824b-4fbb2e121af4', 'sequence': 10, 'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/'}, type='document'),\n",
       " Context(context='find similar data points to given data by comparing their vector representations using distance or similarity metrics. Vectors are numerical representation of unstructured data created from embedding models. You use embedding models to generate vector embeddings of your data and store them in S3 Vectors to perform semantic searches.\\n\\n\\n\\nS3 Vectors introduces vector buckets, a new bucket type with a dedicated set of APIs to store, access, and query vector data without provisioning any infrastructure. When you create an S3 vector bucket, you organize your vector data within vector indexes, making it simple for running similarity search queries against your dataset. Each vector bucket can have up to 10,000 vector indexes, and each vector index can hold tens of millions of vectors.\\n\\nAfter creating a vector index, when adding vector data to the index, you can also attach metadata as key-value pairs to each vector to filter future queries based on a', id='84476c64-1734-4d51-a224-ef44c3e6c4e1', metadata={'sequence': 1, 'id': 'a3633b60-9c8e-4cde-9bba-0dc5c0766fb5', 'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/'}, type='document'),\n",
       " Context(context=\"I'm straving\", id='624153a2-dd1b-4d33-89fe-b6504d751385', metadata={'id': '41a2a885-e0cd-43b8-83d8-f4ccebce0fd6', 'source': 'url'}, type='document'),\n",
       " Context(context='Oh my god, are you ok?', id='90b5fdb4-5002-4cfc-af80-34dd3151e2ef', metadata={'id': 'key2', 'source': 'url'}, type='document')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ee19f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\broverse\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from broverse.flows.offlineflow import get_offline_flow\n",
    "\n",
    "flow = get_offline_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efebc9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of OfflineIndex Flow\n"
     ]
    }
   ],
   "source": [
    "shared = {\n",
    "    \"user_id\": \"000\",\n",
    "    \"username\": \"admin\"\n",
    "}\n",
    "flow.run(shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0d8a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['user_id', 'username', 'document_type', 'source', 'action', 'document_id', 'raw_context', 'contexts', 'vectors'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561cb94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared[\"vectors\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0867ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shared[\"contexts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b157e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Context(context='Title: Introducing Amazon S3 Vectors: First cloud storage with native vector support at scale (preview) | Amazon Web Services\\n\\nURL Source: https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/\\n\\nPublished Time: 2025-07-15T16:33:32-07:00\\n\\nMarkdown Content:\\n![Image 1: Voiced by Polly](https://aws.amazon.com/polly/)\\n\\nToday, we’re announcing the preview of Amazon S3 Vectors, a purpose-built durable vector storage solution that can reduce the total cost of uploading, storing, and querying vectors by up to 90 percent. Amazon S3 Vectors is the first cloud object store with native support to store large vector datasets and provide subsecond query performance that makes it affordable for businesses to store AI-ready data at massive scale.\\n\\nVector search is an emerging technique used in generative AI applications to find similar data points to given data by comparing their vector representations using distance or similarity metrics. Vectors are numerical representation of unstructured data created from embedding models. You use embedding models to generate vector embeddings of your data and store them in S3 Vectors', id='1f306847-6d77-4fee-9146-5b9d3f112a53', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 0}, type='document'),\n",
       " Context(context='find similar data points to given data by comparing their vector representations using distance or similarity metrics. Vectors are numerical representation of unstructured data created from embedding models. You use embedding models to generate vector embeddings of your data and store them in S3 Vectors to perform semantic searches.\\n\\n\\n\\nS3 Vectors introduces vector buckets, a new bucket type with a dedicated set of APIs to store, access, and query vector data without provisioning any infrastructure. When you create an S3 vector bucket, you organize your vector data within vector indexes, making it simple for running similarity search queries against your dataset. Each vector bucket can have up to 10,000 vector indexes, and each vector index can hold tens of millions of vectors.\\n\\nAfter creating a vector index, when adding vector data to the index, you can also attach metadata as key-value pairs to each vector to filter future queries based on a', id='98feef8a-7cd1-46a4-a49c-3e66f998c91d', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 1}, type='document'),\n",
       " Context(context='up to 10,000 vector indexes, and each vector index can hold tens of millions of vectors.\\n\\nAfter creating a vector index, when adding vector data to the index, you can also attach metadata as key-value pairs to each vector to filter future queries based on a set of conditions, for example, dates, categories, or user preferences. As you write, update, and delete vectors over time, S3 Vectors automatically optimizes the vector data to achieve the best possible price-performance for vector storage, even as the datasets scale and evolve.\\n\\n\\n\\nS3 Vectors is also natively integrated with Amazon Bedrock Knowledge Bases, including within Amazon SageMaker Unified Studio, for building cost-effective Retrieval-Augmented Generation (RAG) applications. Through its integration with Amazon OpenSearch Service, you can lower storage costs by keeping infrequent queried vectors in S3 Vectors and then quickly move them to OpenSearch as demands increase or to support real-time, low-latency search operations.\\n\\nWith S3 Vectors, you', id='9e5534fd-5783-405d-8edf-81011314996a', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 2}, type='document'),\n",
       " Context(context='cost-effective Retrieval-Augmented Generation (RAG) applications. Through its integration with Amazon OpenSearch Service, you can lower storage costs by keeping infrequent queried vectors in S3 Vectors and then quickly move them to OpenSearch as demands increase or to support real-time, low-latency search operations.\\n\\nWith S3 Vectors, you can now economically store the vector embeddings that represent massive amounts of unstructured data such as images, videos, documents, and audio files, enabling scalable generative AI applications including semantic and similarity search, RAG, and build agent memory. You can also build applications to support a wide range of industry use cases including personalized recommendations, automated content analysis, and intelligent document processing without the complexity and cost of managing vector databases.\\n\\n**S3 Vectors in action**\\n\\n To create a vector bucket, choose **Vector buckets** in the left navigation pane in the Amazon S3 console and then choose **Create vector bucket**.\\n\\nEnter a vector bucket name and choose the encryption', id='ace21015-6586-49a2-bf5a-e71af1f50459', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 3}, type='document'),\n",
       " Context(context='processing without the complexity and cost of managing vector databases.\\n\\n**S3 Vectors in action**\\n\\n To create a vector bucket, choose **Vector buckets** in the left navigation pane in the Amazon S3 console and then choose **Create vector bucket**.\\n\\nEnter a vector bucket name and choose the encryption type. If you don’t specify an encryption type, Amazon S3 applies server-side encryption with Amazon S3 managed keys (SSE-S3) as the base level of encryption for new vectors. You can also choose server-side encryption with AWS Key Management Service (AWS KMS) keys (SSE-KMS). To learn more about managing your vector bucket, visit S3 Vector buckets in the Amazon S3 User Guide.\\n\\n\\n\\nNow, you can create a vector index to store and query your vector data within your created vector bucket.\\n\\n\\n\\nEnter a vector index name and the dimensionality of the vectors to be inserted in the index. All vectors added to this index must have exactly the', id='debaee0f-4702-4a96-973e-9b968e947ee3', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 4}, type='document'),\n",
       " Context(context='Guide.\\n\\n\\n\\nNow, you can create a vector index to store and query your vector data within your created vector bucket.\\n\\n\\n\\nEnter a vector index name and the dimensionality of the vectors to be inserted in the index. All vectors added to this index must have exactly the same number of values.\\n\\nFor **Distance metric**, you can choose either **Cosine** or **Euclidean**. When creating vector embeddings, select your embedding model’s recommended distance metric for more accurate results.\\n\\n\\n\\nChoose **Create vector index** and then you can insert, list, and query vectors.\\n\\n\\n\\nTo insert your vector embeddings to a vector index, you can use the AWS Command Line Interface (AWS CLI), AWS SDKs, or Amazon S3 REST API. To generate vector embeddings for your unstructured data, you can use embedding models offered by Amazon Bedrock.\\n\\nIf you’re using the latest AWS Python SDKs, you can generate vector embeddings for your text using Amazon Bedrock using following code example:\\n\\n```\\n# Generate', id='d0623acb-6acd-4bec-b7a8-e78879b9bd84', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 5}, type='document'),\n",
       " Context(context='or Amazon S3 REST API. To generate vector embeddings for your unstructured data, you can use embedding models offered by Amazon Bedrock.\\n\\nIf you’re using the latest AWS Python SDKs, you can generate vector embeddings for your text using Amazon Bedrock using following code example:\\n\\n```\\n# Generate and print an embedding with Amazon Titan Text Embeddings V2.\\nimport boto3 \\nimport json \\n\\n# Create a Bedrock Runtime client in the AWS Region of your choice. \\nbedrock= boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\") \\n\\nThe text strings to convert to embeddings.\\ntexts = [\\n\"Star Wars: A farm boy joins rebels to fight an evil empire in space\", \\n\"Jurassic Park: Scientists create dinosaurs in a theme park that goes wrong\",\\n\"Finding Nemo: A father fish searches the ocean to find his lost son\"]\\n\\nembeddings=[]\\n#Generate vector embeddings for the input texts\\nfor text in texts:\\n        body = json.dumps({\\n           ', id='66c2c6a5-9439-4300-a90f-a66cde2af5c1', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 6}, type='document'),\n",
       " Context(context='that goes wrong\",\\n\"Finding Nemo: A father fish searches the ocean to find his lost son\"]\\n\\nembeddings=[]\\n#Generate vector embeddings for the input texts\\nfor text in texts:\\n        body = json.dumps({\\n            \"inputText\": text\\n        })    \\n        # Call Bedrock\\'s embedding API\\n        response = bedrock.invoke_model(\\n        modelId=\\'amazon.titan-embed-text-v2:0\\',  # Titan embedding model \\n        body=body)   \\n        # Parse response\\n        response_body = json.loads(response[\\'body\\'].read())\\n        embedding = response_body[\\'embedding\\']\\n        embeddings.append(embedding)\\n```\\n\\nPython\\n\\nNow, you can insert vector embeddings into', id='143cbb93-5a99-4ec5-bad1-e86f78aa57b2', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 7}, type='document'),\n",
       " Context(context='\\n        # Parse response\\n        response_body = json.loads(response[\\'body\\'].read())\\n        embedding = response_body[\\'embedding\\']\\n        embeddings.append(embedding)\\n```\\n\\nPython\\n\\nNow, you can insert vector embeddings into the vector index and query vectors in your vector index using the query embedding:\\n\\n```\\n# Create S3Vectors client\\ns3vectors = boto3.client(\\'s3vectors\\', region_name=\\'us-west-2\\')\\n\\n# Insert vector embedding\\ns3vectors.put_vectors( vectorBucketName=\"channy-vector-bucket\",\\n  indexName=\"channy-vector-index\", \\n  vectors=[\\n{\"key\": \"v1\", \"data\": {\"float32\": embeddings[0]}, \"metadata\": {\"id\": \"key1\", \"source_text\": texts[0], \"genre\":\"scifi\"}},\\n{\"key\": \"v2\", \"data\": {\"float32\": embeddings[1]}, \"metadata\": {\"id\": \"key2\", \"source_text\": texts[1], \"genre\":\"scifi\"}},\\n{\"key\": \"v3\", \"data\": {\"float32\": embeddings[2]}, \"metadata\": {\"id\": \"key3\", \"source_text\":  texts[2], \"genre\":\"family\"}}\\n],\\n)\\n\\n#Create an embedding for your query input text\\n# The text to convert to an embedding.\\ninput_text = \"List the movies about adventures in space\"\\n\\n# Create the JSON request for the model.\\nrequest = json.dumps({\"inputText\": input_text})\\n\\n# Invoke the model with the request and the model ID, e.g., Titan Text', id='4658ec89-1585-4cdf-9765-61fe56cf639b', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 8}, type='document'),\n",
       " Context(context='an embedding for your query input text\\n# The text to convert to an embedding.\\ninput_text = \"List the movies about adventures in space\"\\n\\n# Create the JSON request for the model.\\nrequest = json.dumps({\"inputText\": input_text})\\n\\n# Invoke the model with the request and the model ID, e.g., Titan Text Embeddings V2. \\nresponse = bedrock.invoke_model(modelId=\"amazon.titan-embed-text-v2:0\", body=request)\\n\\n# Decode the model\\'s native response body.\\nmodel_response = json.loads(response[\"body\"].read())\\n\\n# Extract and print the generated embedding and the input text token count.\\nembedding = model_response[\"embedding\"]\\n\\n# Performa a similarity query. You can also optionally use a filter in your query\\nquery = s3vectors.query_vectors( vectorBucketName=\"channy-vector-bucket\",\\n  indexName=\"channy-vector-index\",\\n  queryVector={\"float32\":embedding},\\n  topK=3, \\n  filter={\"genre\":\"scifi\"},\\n  returnDistance=True,\\n  returnMetadata=True\\n  )\\nresults = query[\"vectors\"]\\nprint(results)\\n```\\n\\nPython\\n\\nTo learn more about inserting vectors into a vector index, or listing, querying, and deleting vectors, visit S3 vector buckets and S3 vector indexes in the Amazon S3 User Guide. Additionally, with the S3 Vectors embed command line interface (CLI), you can create vector', id='acda9ae9-8593-478a-bf00-b762f350697a', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 9}, type='document'),\n",
       " Context(context='= query[\"vectors\"]\\nprint(results)\\n```\\n\\nPython\\n\\nTo learn more about inserting vectors into a vector index, or listing, querying, and deleting vectors, visit S3 vector buckets and S3 vector indexes in the Amazon S3 User Guide. Additionally, with the S3 Vectors embed command line interface (CLI), you can create vector embeddings for your data using Amazon Bedrock and store and query them in an S3 vector index using single commands. For more information, see the S3 Vectors Embed CLI GitHub repository.\\n\\n**Integrate S3 Vectors with other AWS services**\\n\\n S3 Vectors integrates with other AWS services such as Amazon Bedrock, Amazon SageMaker, and Amazon OpenSearch Service to enhance your vector processing capabilities and provide comprehensive solutions for AI workloads.\\n\\n**Create Amazon Bedrock Knowledge Bases with S3 Vectors**\\n\\n You can use S3 Vectors in Amazon Bedrock Knowledge Bases to simplify and reduce the cost of vector storage for RAG applications. When creating a knowledge base in the Amazon Bedrock', id='b707254a-455d-4fcb-906f-3971d2c16456', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 10}, type='document'),\n",
       " Context(context='and provide comprehensive solutions for AI workloads.\\n\\n**Create Amazon Bedrock Knowledge Bases with S3 Vectors**\\n\\n You can use S3 Vectors in Amazon Bedrock Knowledge Bases to simplify and reduce the cost of vector storage for RAG applications. When creating a knowledge base in the Amazon Bedrock console, you can choose the S3 vector bucket as your vector store option.\\n\\nIn **Step 3**, you can choose the **Vector store creation method** either to create an S3 vector bucket and vector index or choose the existing S3 vector bucket and vector index that you’ve previously created.\\n\\n\\n\\nFor detailed step-by-step instructions, visit Create a knowledge base by connecting to a data source in Amazon Bedrock Knowledge Basesin the Amazon Bedrock User Guide.\\n\\n**Using Amazon SageMaker Unified Studio**You can create and manage knowledge bases with S3 Vectors in Amazon SageMaker Unified Studio when you build your generative AI applications through Amazon Bedrock. SageMaker Unified Studio is available in', id='6b4a987a-a38d-4db9-808e-ac9f8da5b2ef', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 11}, type='document'),\n",
       " Context(context='source in Amazon Bedrock Knowledge Basesin the Amazon Bedrock User Guide.\\n\\n**Using Amazon SageMaker Unified Studio**You can create and manage knowledge bases with S3 Vectors in Amazon SageMaker Unified Studio when you build your generative AI applications through Amazon Bedrock. SageMaker Unified Studio is available in the next generation of Amazon SageMaker and provides a unified development environment for data and AI, including building and texting generative AI applications that use Amazon Bedrock knowledge bases.\\n\\n\\n\\nYou can choose **Amazon S3 Vectors** as the **Vector store** when you create a new knowledge bases in the SageMaker Unified Studio. To learn more, visit Add an Amazon Bedrock Knowledge Base component to a chat agent app in the Amazon SageMaker Unified Studio User Guide.\\n\\n**Export S3 vector data to Amazon OpenSearch Service**You can balance cost and performance by adopting a tiered strategy that stores long-term vector data cost-effectively in Amazon S3 while exporting high priority vectors', id='8ffc745a-eb71-4494-a4af-7f1cab83f617', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 12}, type='document'),\n",
       " Context(context='component to a chat agent app in the Amazon SageMaker Unified Studio User Guide.\\n\\n**Export S3 vector data to Amazon OpenSearch Service**You can balance cost and performance by adopting a tiered strategy that stores long-term vector data cost-effectively in Amazon S3 while exporting high priority vectors to OpenSearch for real-time query performance.\\n\\nThis flexibility means your organizations can access OpenSearch’s high performance (high QPS, low latency) for critical, real-time applications, such as product recommendations or fraud detection, while keeping less time-sensitive data in S3 Vectors.\\n\\nTo export your vector index, choose **Advanced search export**, then choose **Export to OpenSearch** in the Amazon S3 console.\\n\\n\\n\\nThen, you will be brought to the Amazon OpenSearch Service Integration console with a template for S3 vector index export to OpenSearch vector engine. Choose **Export** with pre-selected S3 vector source and a service access role.\\n\\n\\n\\nIt will start the steps to create a new OpenSearch Serverless collection and migrate data', id='b29f3a9f-77df-4201-b9b2-36d9980a1b16', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 13}, type='document'),\n",
       " Context(context='to the Amazon OpenSearch Service Integration console with a template for S3 vector index export to OpenSearch vector engine. Choose **Export** with pre-selected S3 vector source and a service access role.\\n\\n\\n\\nIt will start the steps to create a new OpenSearch Serverless collection and migrate data from your S3 vector index into an OpenSearch knn index.\\n\\nChoose the **Import history** in the left navigation pane. You can see the new import job that was created to make a copy of vector data from your S3 vector index into the OpenSearch Serverless collection.\\n\\n\\n\\nOnce the status changes to **Complete**, you can connect to the new OpenSearch serverless collection and query your new OpenSearch knn index.\\n\\nTo learn more, visit Creating and managing Amazon OpenSearch Serverless collections in the Amazon OpenSearch Service Developer Guide.\\n\\n**Now available**Amazon S3 Vectors, and its integrations with Amazon Bedrock, Amazon OpenSearch Service, and Amazon SageMaker are now in preview in the US', id='90941b36-81fb-4f43-adbc-6309bbdef101', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 14}, type='document'),\n",
       " Context(context='query your new OpenSearch knn index.\\n\\nTo learn more, visit Creating and managing Amazon OpenSearch Serverless collections in the Amazon OpenSearch Service Developer Guide.\\n\\n**Now available**Amazon S3 Vectors, and its integrations with Amazon Bedrock, Amazon OpenSearch Service, and Amazon SageMaker are now in preview in the US East (N. Virginia), US East (Ohio), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Sydney) Regions.\\n\\nGive S3 Vectors a try in the Amazon S3 console today and send feedback to AWS re:Post for Amazon S3 or through your usual AWS Support contacts.\\n\\n— Channy\\n\\n_Updated on July 15, 2025 – Revised the console screenshot of Amazon SageMaker Unified Studio._\\n', id='84ae40e6-6cf3-4c91-af59-0ded2bf36a8b', metadata={'source': 'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/', 'sequence': 15}, type='document')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared[\"contexts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03873c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Introducing Amazon S3 Vectors: First cloud storage with native vector support at scale (preview) | Amazon Web Services\\n\\nURL Source: https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/\\n\\nPublished Time: 2025-07-15T16:33:32-07:00\\n\\nMarkdown Content:\\n![Image 1: Voiced by Polly](https://aws.amazon.com/polly/)\\n\\nToday, we’re announcing the preview of Amazon S3 Vectors, a purpose-built durable vector storage solution that can reduce the total cost of uploading, storing, and querying vectors by up to 90 percent. Amazon S3 Vectors is the first cloud object store with native support to store large vector datasets and provide subsecond query performance that makes it affordable for businesses to store AI-ready data at massive scale.\\n\\nVector search is an emerging technique used in generative AI applications to find similar data points to given data by comparing their vector representations using distance or similarity metrics. Vectors are numerical representation of unstructured data created from embedding models. You use embedding models to generate vector embeddings of your data and store them in S3 Vectors to perform semantic searches.\\n\\n\\n\\nS3 Vectors introduces vector buckets, a new bucket type with a dedicated set of APIs to store, access, and query vector data without provisioning any infrastructure. When you create an S3 vector bucket, you organize your vector data within vector indexes, making it simple for running similarity search queries against your dataset. Each vector bucket can have up to 10,000 vector indexes, and each vector index can hold tens of millions of vectors.\\n\\nAfter creating a vector index, when adding vector data to the index, you can also attach metadata as key-value pairs to each vector to filter future queries based on a set of conditions, for example, dates, categories, or user preferences. As you write, update, and delete vectors over time, S3 Vectors automatically optimizes the vector data to achieve the best possible price-performance for vector storage, even as the datasets scale and evolve.\\n\\n\\n\\nS3 Vectors is also natively integrated with Amazon Bedrock Knowledge Bases, including within Amazon SageMaker Unified Studio, for building cost-effective Retrieval-Augmented Generation (RAG) applications. Through its integration with Amazon OpenSearch Service, you can lower storage costs by keeping infrequent queried vectors in S3 Vectors and then quickly move them to OpenSearch as demands increase or to support real-time, low-latency search operations.\\n\\nWith S3 Vectors, you can now economically store the vector embeddings that represent massive amounts of unstructured data such as images, videos, documents, and audio files, enabling scalable generative AI applications including semantic and similarity search, RAG, and build agent memory. You can also build applications to support a wide range of industry use cases including personalized recommendations, automated content analysis, and intelligent document processing without the complexity and cost of managing vector databases.\\n\\n**S3 Vectors in action**\\n\\n To create a vector bucket, choose **Vector buckets** in the left navigation pane in the Amazon S3 console and then choose **Create vector bucket**.\\n\\nEnter a vector bucket name and choose the encryption type. If you don’t specify an encryption type, Amazon S3 applies server-side encryption with Amazon S3 managed keys (SSE-S3) as the base level of encryption for new vectors. You can also choose server-side encryption with AWS Key Management Service (AWS KMS) keys (SSE-KMS). To learn more about managing your vector bucket, visit S3 Vector buckets in the Amazon S3 User Guide.\\n\\n\\n\\nNow, you can create a vector index to store and query your vector data within your created vector bucket.\\n\\n\\n\\nEnter a vector index name and the dimensionality of the vectors to be inserted in the index. All vectors added to this index must have exactly the same number of values.\\n\\nFor **Distance metric**, you can choose either **Cosine** or **Euclidean**. When creating vector embeddings, select your embedding model’s recommended distance metric for more accurate results.\\n\\n\\n\\nChoose **Create vector index** and then you can insert, list, and query vectors.\\n\\n\\n\\nTo insert your vector embeddings to a vector index, you can use the AWS Command Line Interface (AWS CLI), AWS SDKs, or Amazon S3 REST API. To generate vector embeddings for your unstructured data, you can use embedding models offered by Amazon Bedrock.\\n\\nIf you’re using the latest AWS Python SDKs, you can generate vector embeddings for your text using Amazon Bedrock using following code example:\\n\\n```\\n# Generate and print an embedding with Amazon Titan Text Embeddings V2.\\nimport boto3 \\nimport json \\n\\n# Create a Bedrock Runtime client in the AWS Region of your choice. \\nbedrock= boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\") \\n\\nThe text strings to convert to embeddings.\\ntexts = [\\n\"Star Wars: A farm boy joins rebels to fight an evil empire in space\", \\n\"Jurassic Park: Scientists create dinosaurs in a theme park that goes wrong\",\\n\"Finding Nemo: A father fish searches the ocean to find his lost son\"]\\n\\nembeddings=[]\\n#Generate vector embeddings for the input texts\\nfor text in texts:\\n        body = json.dumps({\\n            \"inputText\": text\\n        })    \\n        # Call Bedrock\\'s embedding API\\n        response = bedrock.invoke_model(\\n        modelId=\\'amazon.titan-embed-text-v2:0\\',  # Titan embedding model \\n        body=body)   \\n        # Parse response\\n        response_body = json.loads(response[\\'body\\'].read())\\n        embedding = response_body[\\'embedding\\']\\n        embeddings.append(embedding)\\n```\\n\\nPython\\n\\nNow, you can insert vector embeddings into the vector index and query vectors in your vector index using the query embedding:\\n\\n```\\n# Create S3Vectors client\\ns3vectors = boto3.client(\\'s3vectors\\', region_name=\\'us-west-2\\')\\n\\n# Insert vector embedding\\ns3vectors.put_vectors( vectorBucketName=\"channy-vector-bucket\",\\n  indexName=\"channy-vector-index\", \\n  vectors=[\\n{\"key\": \"v1\", \"data\": {\"float32\": embeddings[0]}, \"metadata\": {\"id\": \"key1\", \"source_text\": texts[0], \"genre\":\"scifi\"}},\\n{\"key\": \"v2\", \"data\": {\"float32\": embeddings[1]}, \"metadata\": {\"id\": \"key2\", \"source_text\": texts[1], \"genre\":\"scifi\"}},\\n{\"key\": \"v3\", \"data\": {\"float32\": embeddings[2]}, \"metadata\": {\"id\": \"key3\", \"source_text\":  texts[2], \"genre\":\"family\"}}\\n],\\n)\\n\\n#Create an embedding for your query input text\\n# The text to convert to an embedding.\\ninput_text = \"List the movies about adventures in space\"\\n\\n# Create the JSON request for the model.\\nrequest = json.dumps({\"inputText\": input_text})\\n\\n# Invoke the model with the request and the model ID, e.g., Titan Text Embeddings V2. \\nresponse = bedrock.invoke_model(modelId=\"amazon.titan-embed-text-v2:0\", body=request)\\n\\n# Decode the model\\'s native response body.\\nmodel_response = json.loads(response[\"body\"].read())\\n\\n# Extract and print the generated embedding and the input text token count.\\nembedding = model_response[\"embedding\"]\\n\\n# Performa a similarity query. You can also optionally use a filter in your query\\nquery = s3vectors.query_vectors( vectorBucketName=\"channy-vector-bucket\",\\n  indexName=\"channy-vector-index\",\\n  queryVector={\"float32\":embedding},\\n  topK=3, \\n  filter={\"genre\":\"scifi\"},\\n  returnDistance=True,\\n  returnMetadata=True\\n  )\\nresults = query[\"vectors\"]\\nprint(results)\\n```\\n\\nPython\\n\\nTo learn more about inserting vectors into a vector index, or listing, querying, and deleting vectors, visit S3 vector buckets and S3 vector indexes in the Amazon S3 User Guide. Additionally, with the S3 Vectors embed command line interface (CLI), you can create vector embeddings for your data using Amazon Bedrock and store and query them in an S3 vector index using single commands. For more information, see the S3 Vectors Embed CLI GitHub repository.\\n\\n**Integrate S3 Vectors with other AWS services**\\n\\n S3 Vectors integrates with other AWS services such as Amazon Bedrock, Amazon SageMaker, and Amazon OpenSearch Service to enhance your vector processing capabilities and provide comprehensive solutions for AI workloads.\\n\\n**Create Amazon Bedrock Knowledge Bases with S3 Vectors**\\n\\n You can use S3 Vectors in Amazon Bedrock Knowledge Bases to simplify and reduce the cost of vector storage for RAG applications. When creating a knowledge base in the Amazon Bedrock console, you can choose the S3 vector bucket as your vector store option.\\n\\nIn **Step 3**, you can choose the **Vector store creation method** either to create an S3 vector bucket and vector index or choose the existing S3 vector bucket and vector index that you’ve previously created.\\n\\n\\n\\nFor detailed step-by-step instructions, visit Create a knowledge base by connecting to a data source in Amazon Bedrock Knowledge Basesin the Amazon Bedrock User Guide.\\n\\n**Using Amazon SageMaker Unified Studio**You can create and manage knowledge bases with S3 Vectors in Amazon SageMaker Unified Studio when you build your generative AI applications through Amazon Bedrock. SageMaker Unified Studio is available in the next generation of Amazon SageMaker and provides a unified development environment for data and AI, including building and texting generative AI applications that use Amazon Bedrock knowledge bases.\\n\\n\\n\\nYou can choose **Amazon S3 Vectors** as the **Vector store** when you create a new knowledge bases in the SageMaker Unified Studio. To learn more, visit Add an Amazon Bedrock Knowledge Base component to a chat agent app in the Amazon SageMaker Unified Studio User Guide.\\n\\n**Export S3 vector data to Amazon OpenSearch Service**You can balance cost and performance by adopting a tiered strategy that stores long-term vector data cost-effectively in Amazon S3 while exporting high priority vectors to OpenSearch for real-time query performance.\\n\\nThis flexibility means your organizations can access OpenSearch’s high performance (high QPS, low latency) for critical, real-time applications, such as product recommendations or fraud detection, while keeping less time-sensitive data in S3 Vectors.\\n\\nTo export your vector index, choose **Advanced search export**, then choose **Export to OpenSearch** in the Amazon S3 console.\\n\\n\\n\\nThen, you will be brought to the Amazon OpenSearch Service Integration console with a template for S3 vector index export to OpenSearch vector engine. Choose **Export** with pre-selected S3 vector source and a service access role.\\n\\n\\n\\nIt will start the steps to create a new OpenSearch Serverless collection and migrate data from your S3 vector index into an OpenSearch knn index.\\n\\nChoose the **Import history** in the left navigation pane. You can see the new import job that was created to make a copy of vector data from your S3 vector index into the OpenSearch Serverless collection.\\n\\n\\n\\nOnce the status changes to **Complete**, you can connect to the new OpenSearch serverless collection and query your new OpenSearch knn index.\\n\\nTo learn more, visit Creating and managing Amazon OpenSearch Serverless collections in the Amazon OpenSearch Service Developer Guide.\\n\\n**Now available**Amazon S3 Vectors, and its integrations with Amazon Bedrock, Amazon OpenSearch Service, and Amazon SageMaker are now in preview in the US East (N. Virginia), US East (Ohio), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Sydney) Regions.\\n\\nGive S3 Vectors a try in the Amazon S3 console today and send feedback to AWS re:Post for Amazon S3 or through your usual AWS Support contacts.\\n\\n— Channy\\n\\n_Updated on July 15, 2025 – Revised the console screenshot of Amazon SageMaker Unified Studio._\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared[\"raw_context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89860d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://aws.amazon.com/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e1ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3vectors = boto3.client('s3vectors', region_name='us-west-2')\n",
    "response = s3vectors.delete_index(\n",
    "    vectorBucketName='test-broverse-20250729',\n",
    "    indexName='test-url-index',\n",
    "    # indexArn=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9998d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Hi\n",
      "USER INTENT: continue\n",
      "AI: How can I assist you today?\n",
      "You: exit\n",
      "End of Online Flow\n"
     ]
    }
   ],
   "source": [
    "from broverse.flows.onlineflow import get_online_flow\n",
    "\n",
    "shared = {}\n",
    "\n",
    "flow = get_online_flow()\n",
    "flow.run(shared=shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf866b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_input': '',\n",
       " 'action': 'chat',\n",
       " 'messages': [{'role': 'user', 'content': [{'text': 'Hi there!'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'text': \"It's nice to meet you. Is there something I can help you with or would you like to chat?\"}]},\n",
       "  {'role': 'user', 'content': [{'text': 'How ya been?'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'text': \"I've been doing well, thanks for asking. I'm a large language model, so I don't have feelings or experiences like humans do, but I'm always happy to chat and help with any questions or topics you'd like to discuss. How about you? How's your day going so far?\"}]},\n",
       "  {'role': 'user', 'content': [{'text': 'Good Good'}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'text': \"It's great to hear that. If you're feeling good, I'm happy to keep the conversation going. We could talk about your interests, hobbies, or anything else that's on your mind. Or if you're feeling relaxed, we could just chat about random things and see where the conversation takes us. What sounds good to you?\"}]},\n",
       "  {'role': 'user', 'content': [{'text': ''}]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388639e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
